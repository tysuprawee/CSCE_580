{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resume Word Analysis\n",
    "This notebook analyzes the frequency of words in a resume and visualizes the top terms before and after removing stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "\n",
    "resume_path = Path('Q2/data/suprawee_resume.txt')\n",
    "stop_words_path = Path('Q2/data/stop_words.txt')\n",
    "figures_dir = Path('Q2/figures')\n",
    "figures_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def save_svg_bar(data, filename, title):\n",
    "    width = 800\n",
    "    height = 400\n",
    "    bar_width = width / len(data)\n",
    "    max_count = max(count for _, count in data)\n",
    "    scale = (height - 50) / max_count\n",
    "    svg_parts = [f'<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"{width}\" height=\"{height}\">']\n",
    "    svg_parts.append(f'<text x=\"{width/2}\" y=\"20\" text-anchor=\"middle\" font-size=\"16\" fill=\"white\">{title}</text>')\n",
    "    for i, (word, count) in enumerate(data):\n",
    "        x = i * bar_width\n",
    "        bar_height = count * scale\n",
    "        y = height - bar_height - 20\n",
    "        svg_parts.append(f'<rect x=\"{x}\" y=\"{y}\" width=\"{bar_width-2}\" height=\"{bar_height}\" fill=\"steelblue\"/>')\n",
    "        svg_parts.append(f'<text x=\"{x + bar_width/2}\" y=\"{height - 5}\" text-anchor=\"middle\" font-size=\"10\" transform=\"rotate(45 {x + bar_width/2},{height - 5})\" fill=\"white\">{word}</text>')\n",
    "    svg_parts.append('</svg>')\n",
    "    Path(filename).write_text('\n'.join(svg_parts), encoding='utf-8')\n",
    "\n",
    "text = resume_path.read_text(encoding='utf-8')\n",
    "words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "word_counts = Counter(words)\n",
    "top_resume = word_counts.most_common(20)\n",
    "save_svg_bar(top_resume, figures_dir/'resume_words.svg', 'Top 20 Resume Words')\n",
    "top_resume[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stop_words_path.read_text(encoding='utf-8').split())\n",
    "specific_words = [w for w in words if w not in stop_words]\n",
    "specific_counts = Counter(specific_words)\n",
    "top_specific = specific_counts.most_common(20)\n",
    "save_svg_bar(top_specific, figures_dir/'specific_words.svg', 'Top 20 Specific Words')\n",
    "top_specific[:5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing common stop words reveals keywords that emphasize technical skills and experiences, such as **developed**, **python**, and **project**, giving more insight into the resume's content."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Resume Word Analysis\n",
    "Analyze word usage across all resumes in the class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "resumes_dir = Path('Q2/data/resumes')\n",
    "all_text = []\n",
    "for pdf_path in sorted(resumes_dir.glob('*.pdf')):\n",
    "    try:\n",
    "        reader = PdfReader(str(pdf_path))\n",
    "        text = ''\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text() or ''\n",
    "        all_text.append(text)\n",
    "    except Exception as e:\n",
    "        print(f'Failed to read {pdf_path}: {e}')\n",
    "class_text = '\n'.join(all_text)\n",
    "Path('Q2/data/resumes_text.txt').write_text(class_text, encoding='utf-8')\n",
    "class_words = re.findall(r'\\b\\w+\\b', class_text.lower())\n",
    "class_counts = Counter(class_words)\n",
    "top_class = class_counts.most_common(20)\n",
    "save_svg_bar(top_class, figures_dir/'class_resume_words.svg', 'Top 20 Resume Words (Class)')\n",
    "top_class[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_specific_words = [w for w in class_words if w not in stop_words]\n",
    "class_specific_counts = Counter(class_specific_words)\n",
    "top_class_specific = class_specific_counts.most_common(20)\n",
    "save_svg_bar(top_class_specific, figures_dir/'class_specific_words.svg', 'Top 20 Specific Words (Class)')\n",
    "top_class_specific[:5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing stop words across all resumes highlights technical and domain-specific terms that reflect common skills among classmates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_specific_set = set(specific_words)\n",
    "class_specific_set = set(class_specific_words)\n",
    "unique_words = sorted(my_specific_set - class_specific_set)[:20]\n",
    "unique_words\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These words appear only in my resume, distinguishing my experiences from those of classmates.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}